---
title: Math, Grit and Multilevel Models (part 1)
author: Edi Terlaak
date: '2021-01-25'
slug: math-grit-and-multilevel-models-part-1
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-01-25T17:20:46+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


Students are often told that perseverance pays off in the end. But does it? And if it does, can it be instilled in students? According to the authors of a large experiment in Turkey, the answer to these questions is yes. In this blogpost we scrutinze their results, which have been made public [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910/DVN/SAVGAL) in an exemplary way.  

We use data from the second wave of the study, because it allows us to make causal inferences. We load r packages together with the data, mutate categorical variables, and have a quick look at the variables.  

```{r data, warning = FALSE, message = FALSE}
library(haven)
library(tidyverse)
library(naniar)
library(here)
library(brms)
library(mice)
library(ggthemes)
library(patchwork)
library(tinytex)
library(forcats) 

# second sample of 1499 students
data2 <- read_dta(here("content/post/2021-01-25-math-grit-and-multilevel-models-part-1/Sample2_Data.dta"))

# variables with common words can be factorized more efficiently
data2 <- data2 %>% mutate_at(vars(matches("choice")), as.factor) %>% 
                    mutate_at(vars(matches("success")), as.factor) %>% 
                    mutate_at(vars(matches("payoff")), as.factor) %>%     
                    mutate_at(vars(matches("difficult")), as.factor)

# the rest is done by hand
cols <- c("sample", "schoolid", "classid", "grit", "task_ability", "playedr1", "alldiff", "playedv2", "inconsistent", "male", "risk", "wealth")

data2 <- data2 %>% mutate_at(cols, funs(factor(.)))

# We rename the grit variable to clarify its importance
data2 <- data2 %>%  mutate(grit = fct_recode(grit,
                    "control" = "0",
                    "intervention" = "1"))

glimpse(data2)

```

We notice that numeric variables have already been standardized. This makes comparisons of their relative effects easier.

### Visual exploration

For the experiment 16 schools were randomly divided into a control and intervention group. In the intervention group students followed a special training program to increase their grit. Let us see how schools, classes and students were divided over the two groups. 

```{r students_per_group, warning=FALSE, message=FALSE}
data2 %>% group_by(grit) %>% 
  summarize(count_school = n_distinct(schoolid),
            count_class = n_distinct(classid), 
            count_students = n_distinct(studentid))
```
Whereas schools were divided evenly over the groups, classes and students were not. This confirms that the researchers exerted control over the allocation of schools, but not over classes and students. 

Regardless, the graphs below show that properties such as raven IQ and verbal scores are pretty evenly distributed among the two groups. This is not true for wealth though, a variable that measures the income group of the parents.

```{r two_groups, warning=FALSE}

p1 <- data2 %>% ggplot(aes(x=raven)) +
  geom_density() +
  facet_wrap(~ grit, nrow=2) +
  labs(x="raven IQ score") +
  theme_tufte() +
    theme(
    panel.border = element_rect(colour = "black", fill=NA, size=1),
    strip.background = element_rect(
     color="black", fill="#F9EBEA", size=1.5, linetype="solid"
     ))

p2 <- data2 %>% drop_na() %>% 
  ggplot(aes(x=wealth)) +
  geom_bar(aes(x = wealth, y = ..prop.., group=1), stat = "count") +
  facet_wrap(~ grit, nrow=2)+
  labs(y="proportion") +
  theme_tufte()+
    theme(
    panel.border = element_rect(colour = "black", fill=NA, size=1),
    strip.background = element_rect(
     color="black", fill="#F9EBEA", size=1.5, linetype="solid"
     ))

p3 <- data2 %>% group_by(grit) %>% ggplot(aes(x=verbalscore1)) +
  geom_bar(aes(x = verbalscore1, y = ..prop..), stat = "count", width=0.7) +
  facet_wrap(~ grit, nrow=2)+
  labs(x="verbal score 1", y="proportion") +
  theme_tufte()+
    theme(
    panel.border = element_rect(colour = "black", fill=NA, size=1),
    strip.background = element_rect(
     color="black", fill="#F9EBEA", size=1.5, linetype="solid"
     ))

p1 + p3 +p2 


```

In order to get a feel for the impact of the experiment, we split out the effect of grit on the differences in scores on a math test before and after the intervention. 

```{r plotting_scores_by_wealth}
data2 <- data2 %>% mutate(math_diff = mathscore2-mathscore1)

ggplot(data = na.omit(data2[c("grit", "wealth", "math_diff")]), aes(factor(wealth), math_diff)) +
  geom_boxplot() +
  facet_wrap(~ factor(grit)) +
  labs(y="difference in math scores",
       x= "wealth groups") +
  geom_hline(yintercept = 0, color="red", size=1) +
  theme_tufte() +
  theme(
    panel.border = element_rect(colour = "black", fill=NA, size=1),
    strip.background = element_rect(
     color="black", fill="#F9EBEA", size=1.5, linetype="solid"
     ))
```
There is some movement in the intervention group. Pupils from lower wealth classes seem to benefit from the grit intervention, whereas those from higher wealth classes may suffer. 

Let us also quickly check if the difference in math scores depends on the skill level of the student. To this end we draw a least squares line that fits the score on the second math test based on the first. We do this both for students in the control group and for those in the intervention group. The transparent grey band around the lines are 95% confidence intervals.  

```{r plotting_diffmath_by_grit, warning=FALSE}

data2 %>% ggplot(aes(x=mathscore1, y=mathscore2, color=grit)) +
  geom_jitter() +
  geom_smooth(method="lm") +
  scale_color_manual(values=c("grey", "red")) +
  theme_tufte() +
  theme(
    panel.border = element_rect(colour = "black", fill=NA, size=1))

```
The graph can be interpreted as follows. Suppose we were given a student's score on the first math test and asked to predict the score on the second math test. In that case we would predict a larger increase if we were also told that the student was in the intervention group. We would do so confidently if the student had a low score on the first test and less so if the initial score was higher. This makes sense. Fostering grit is likely to benefit those who need to work the hardest for a good score.   

### Missing values
Next, we want to get an overview of missing values.

```{r}
vis_miss(data2)
```
We note that about 10% of values are missing. Let's look at hotspots of missingsness.

```{r}
gg_miss_upset(data2)
```
The main culprits are mathscore3 and verbalscore3, which is as expected given that mathscore1 and mathscore2 were obtained right before and after the experiment, while mathscore3 was collected two and a half years later. 

Leaving the missing data out is a bad idea, because they could bias results and increase the standard error. Below we see that the missingness of scores on the math tests is not distributed evenly over the control and intervention groups, for example.

```{r}

data2 %>% 
  select(mathscore2, grit, mathscore3) %>%
  group_by(grit) %>% 
  summarise_all(funs(sum(is.na(.))))
```

So instead we impute values. That is, we carry out a bunch of regressions in several orders until the imputed values converge. The regression models have an error component however, such as the standard deviation for a standard linear regression. When we predict one value from such a model, it will be a little different every time. We deal with this problem by making many predictions, and storing them in several data sets, which we will then all feed into the model that we use for our analysis. The package `mice` does the imputation for us. We only need to specify which method should be used for which type of variable.

```{r mice, warning=FALSE}

data2_imp <- mice(data2, m = 5, 
                         defaultMethod =c("cart", "lda", "pmm", "polr"),
                  file="fits/data2_imp")

stripplot(data2_imp, verbalscore3 ~ age | .imp, pch = 20, cex = 0.1,
                    jitter.data = TRUE)

stripplot(data2_imp, mathscore3 ~ age | .imp, pch = 20, cex = 0.1,
                    jitter.data = TRUE)

stripplot(data2_imp, age ~ mathscore2 | .imp, pch = 20, cex = 0.1,
                    factor=2,
                    jitter.data = TRUE)
```
The graphs of the imputation process suggest that we haven't imputed any crazy values. 