---
title: Mixing up Math (part 1)
author: Edi Terlaak
date: '2021-03-13'
slug: mixing-up-math-part-1
categories:
  - R
tags:
  - education
subtitle: ''
summary: ''
authors: []
lastmod: '2021-03-13T15:59:58+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<p>According to a number of psychologists, we’ve been teaching math the wrong way. Instead of hammering away on the same topic for weeks, learners of math should mix up, or <em>interleave</em>, the concepts they practice. In a 2019 study, Doug Rohrer and colleagues claim to show that interleaved practice can have an effect size of no less than 0,8 (compared to standard <em>blocked</em> practice). For educational research this is a spectacular effect size. So let’s dive into the details of the study and see if we can replicate the results.</p>
<div id="research-design" class="section level3">
<h3>Research Design</h3>
<p>The study consists of a so called field experiment. That means that the study was not performed under controlled conditions in a university room, but at several schools in Florida. One group of seventh grade kids received interleaved practice questions and the other group received blocked practice material. The questions were the same, so that only the ordering differed between the two groups. After practicing for about three months, the same surprise test was taken by all the kids.</p>
<p>In order to clearly identify what the critical issues with the study design are, we introduce some standard notation on causality. An annoying fact for the purpose of an analysis of causality is that we only ever observe one outcome of an event. If we are dealing with a suspected cause that we call treatment <span class="math inline">\(T_{i}\)</span>, then for individual <span class="math inline">\(i\)</span> we may only observe <span class="math inline">\(Y_{i}(1)\)</span> and not <span class="math inline">\(Y_{i}(0)\)</span>. That is, for person <span class="math inline">\(i\)</span> we may only observe the effect of <span class="math inline">\(T_{i}=1\)</span> at any one point in time. We could measure the outcome at a later point in time, where we could make sure that <span class="math inline">\(T_{i}=0\)</span>, but then not all the conditions will be <em>exactly</em> the same. So we can never solve the fundamental problem of what would have happened if things would have been different.</p>
<p>At this point one can either give up, or carry on pragmatically and - as one does so often in statistics in all kinds of guises - take the average of many responses to <span class="math inline">\(T_{i}=1\)</span> and <span class="math inline">\(T_{i}=0\)</span>. This give us the average treatment effect that we will here simply write as <span class="math inline">\(Y(1)-Y(0)\)</span>.</p>
<p>There are two more problems though. One is the standard problem of inference to the larger population and the second is that of confounders. These can either be observed or unobserved. We write the observed confounders as <span class="math inline">\(X\)</span> and the unobserved as <span class="math inline">\(U\)</span>. The problem with confounders is of course that if the treatment <span class="math inline">\(T_{i}=1\)</span> goes together with <span class="math inline">\(X\)</span> or <span class="math inline">\(U\)</span>, we can mistakenly conclude that <span class="math inline">\(T\)</span> is doing the causal work. Confounders can cause error at two stages. The first occurs when a sample is taken and is denoted as <span class="math inline">\(\Delta_{S}\)</span> and the second arises from assigning the treatment and is hence written as <span class="math inline">\(\Delta_{T}\)</span>. In both cases there are two types of confounders, so that what we are minimizing is</p>
<p><span class="math display">\[Estimation\ error=(\Delta_{S_{X}}+\Delta_{S_{U}}) + (\Delta_{T_{X}}+\Delta_{T_{U}})\]</span>.
With regard to the sample part of the error in the estimation of the treatment effect, the authors have made no effort to select a random sample of the US or even Florida population. They persuaded five schools within a 30 min drive from their university to participate in the study and excluded schools that were low performers. There is reason to believe that students in Florida are not that different from at least students in other Western countries with respect to learning math. The effect may also hold only for the four math topics in the experiment that we will discuss shortly and not for others. In both cases it seems reasonable to assume that the results generalize to a wider population because the intervention is at such a fundamental level, but we should realize that they are assumptions.</p>
<p>The second part of the error concern treatment assignment. Here the authors took care to assign treatments randomly. In this case the unit that was assigned the treatment was the class, for obvious logistical reasons. The randomization assures that <span class="math inline">\((\Delta_{T_{X}}+\Delta_{T_{U}})\)</span> goes to 0 in the limit. But for every finite sample, confounders could be unevenly distributed between the groups. The researchers therefore used a blocked design, which means that the confounder <code>Teacher</code> was evenly divided between the two groups. In practice, only teachers that taught several classes of the same level were included and evenly assigned <code>blocked</code> and <code>interleaved</code> classes. Read more on the advantages of blocked randomization <a href="https://gking.harvard.edu/files/abs/matchse-abs.shtml">here</a>.</p>
<p>This means that <span class="math inline">\(\Delta_{T_{X}}\)</span> has been set to exactly 0 by design for <span class="math inline">\(X\)</span> = teacher effects. There can of course still be other confounders <span class="math inline">\(U\)</span>. The expected value of the difference in <span class="math inline">\(U\)</span> between the two groups is 0, but not that many units have been assigned randomly. There are 787 students in the study, but only 54 classes have been assigned randomly to the two conditions. We will explore the consequences in part 2, where we turn to inference.</p>
</div>
<div id="the-data" class="section level3">
<h3>The data</h3>
<p>Let’s confirm these numbers by looking at the structure of the data set that is shared publicly <a href="https://osf.io/7h9p3/">here</a>.</p>
<pre class="r"><code># Classes are distributed per teacher
rohrer %&gt;% group_by(School,Teacher, Class, Group) %&gt;% 
  summarize(n = n()) %&gt;% 
  print(n=10)</code></pre>
<pre><code>## `summarise()` regrouping output by &#39;School&#39;, &#39;Teacher&#39;, &#39;Class&#39; (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 54 x 5
## # Groups:   School, Teacher, Class [54]
##    School Teacher Class Group     n
##    &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt;
##  1 A            1     1 inter     7
##  2 A            1     2 block    20
##  3 A            1     3 block    19
##  4 A            1     4 inter     4
##  5 A            2     1 inter    19
##  6 A            2     2 block    12
##  7 A            2     3 inter    17
##  8 A            2     4 block    13
##  9 A            3     1 block     6
## 10 A            3     2 inter    14
## # ... with 44 more rows</code></pre>
<p>The table below demonstrates that students are distributed more or less equally among the groups.</p>
<pre class="r"><code># students per Group
rohrer %&gt;% group_by(Group) %&gt;% 
  summarize(n=n())</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## # A tibble: 2 x 2
##   Group     n
##   &lt;chr&gt; &lt;int&gt;
## 1 block   389
## 2 inter   398</code></pre>
<p>After three months of practicing a surprise test was taken. It contained 16 questions on 4 topics:</p>
<ul>
<li>Writing proportional formulas</li>
<li>Algebra with parentheses</li>
<li>Solving inequalities</li>
<li>Calculations on circles</li>
</ul>
<p>We create variables with subscores on these 4 topics on the surprise test, as well as their sum.</p>
<pre class="r"><code># summing individual scores into total and standardize. Also summing partial scores 
rohrer &lt;- rohrer %&gt;% mutate(total = rowSums(.[grep(&quot;[A-Z]+[1-4]&quot;, names(.))]),
                            stand_total = (total - mean(total))/sd(total),
                            prop_formula = rowSums(.[grep(&quot;[G]+[1-4]&quot;, names(.))]),
                            inequality = rowSums(.[grep(&quot;[I]+[1-4]&quot;, names(.))]),
                            parentheses = rowSums(.[grep(&quot;[E]+[1-4]&quot;, names(.))]),
                            circle = rowSums(.[grep(&quot;[C]+[1-4]&quot;, names(.))]))

# rename levels of the factor Group (for readability graphs)
rohrer &lt;- rohrer %&gt;% mutate(Group = as.factor(Group),
                            Group = fct_recode(Group,
                                               &quot;blocked&quot; = &quot;block&quot;,
                                               &quot;interleaved&quot; = &quot;inter&quot;)) </code></pre>
</div>
<div id="visual-exploration" class="section level3">
<h3>Visual Exploration</h3>
<p>We first inspect the results of students in the two groups per school visually.</p>
<pre class="r"><code># Results total by School and Group in a histogram; alpha can be adjusted to make colors appear; 
# beware though, as they distract
rohrer %&gt;% ggplot(aes(x=total)) +
  geom_histogram(binwidth=1, color=&quot;black&quot;, fill=&quot;grey&quot;) +
  facet_grid(rows= vars(Group), cols= vars(School), labeller = label_both) +
  geom_rect(data=subset(rohrer, Group == &quot;blocked&quot;), 
            aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf), 
            fill=&quot;red&quot;, alpha=0.0015) +
  geom_rect(data=subset(rohrer, Group == &quot;interleaved&quot;), 
            aes(xmin=-Inf, xmax=Inf, ymin=-Inf, ymax=Inf), 
            fill=&quot;blue&quot;, alpha=0.0015) +
  theme_classic() +
  theme(
    panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size=1),
    strip.background = element_rect(
      color=&quot;black&quot;, fill=&quot;white&quot;, size=1.5, linetype=&quot;solid&quot;)) +
  ylab(&quot;number of students&quot;) +
  xlab(&quot;points scored&quot;) +
  ggtitle(&quot;The effect of interleaving per school&quot;)</code></pre>
<p><img src="/post/2021-03-13-mixing-up-math-part-1/index.en_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We observe a dramatic difference in performance among the two groups in all schools.</p>
<p>Zooming in, we compare students that were taught by the same teacher, but were either in the blocked or interleaved group.</p>
<pre class="r"><code># row and col names have to be assigned manually because automatic ones don&#39;t fit
Teach1 &lt;- c(&quot;Teacher 1&quot;, &quot;Teacher 2&quot;,&quot;Teacher 3&quot;,&quot;Teacher 4&quot;,&quot;Teacher 5&quot;)
names(Teach1) &lt;- c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;)
Teach2 &lt;- c(&quot;Teacher 6&quot;, &quot;Teacher 7&quot;,&quot;Teacher 8&quot;,&quot;Teacher 9&quot;,&quot;Teacher 10&quot;)
names(Teach2) &lt;- c(&quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;, &quot;10&quot;)
Teach3 &lt;- c(&quot;Teacher 11&quot;, &quot;Teacher 12&quot;,&quot;Teacher 13&quot;,&quot;Teacher 14&quot;,&quot;Teacher 15&quot;)
names(Teach3) &lt;- c(&quot;11&quot;, &quot;12&quot;, &quot;13&quot;, &quot;14&quot;, &quot;15&quot;)
Group1 &lt;- c(&quot;block&quot;, &quot;inter&quot;)
names(Group1) &lt;- c(&quot;blocked&quot;, &quot;interleaved&quot;)

# facet_grid cannot cut up the grid, so we write a function to do it ourselves
# arguments in function: l = left bound, r = right bound, t = teacher names
teach_graph &lt;- function(l,r,t){
  rohrer %&gt;% filter(Teacher &gt; l &amp; Teacher &lt;= r) %&gt;% ggplot(aes(x=total)) +
    geom_histogram(binwidth=1, color=&quot;black&quot;, fill=&quot;grey&quot;) +
    scale_y_continuous(breaks=seq(0,10,5)) +
    facet_grid(rows= vars(Group), cols= vars(Teacher), labeller = labeller(Group = Group1, Teacher = t)) +
    theme_classic() +
    theme(
      panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size=1),
      strip.background = element_rect(
        color=&quot;black&quot;, fill=&quot;white&quot;, size=1.5, linetype=&quot;solid&quot;)) +
    xlab(NULL) +
    ylab(NULL)
} 

# Create three histograms
p1 &lt;- teach_graph(0,5,Teach1)
p2 &lt;- teach_graph(5,10,Teach2) +
  ylab(&quot;number of students&quot;) +
  xlab(NULL)
p3 &lt;- teach_graph(10,15,Teach3)+
  xlab(&quot;points scored&quot;) +
  ylab(NULL)

# We use patchwork to glue them together in the order that we desire
p1/ p2/ p3</code></pre>
<p><img src="/post/2021-03-13-mixing-up-math-part-1/index.en_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Here the results are more ambiguous. For some teachers we observe the same stark difference in test results in favor of the interleaved group. But for others the results seem quite similar at first glance. There seems then to be significant variation between teachers in the difference between the groups. This topic will be explored in depth in the analysis in part 2.</p>
<p>So far we have looked at the total score on the surprise test. We now split up the scores in the four topics that were covered. The order matters here. In the <code>blocked</code> condition students first completed questions on formulas for proportional relations, solved inequalities in the second block, etc. We notice a clear pattern.</p>
<pre class="r"><code># Write a function for making a histogram based on input data
hist_scores &lt;- function(data){
  ggplot(rohrer) +
  geom_histogram(binwidth=1, color=&quot;black&quot;, fill=&quot;grey&quot;, aes(y=data)) +
  coord_flip() +
  facet_grid(vars(Group)) +
  theme_classic()
}

# Histograms for the four types of questions
h1 &lt;- hist_scores(rohrer$prop_formula) + ylab(&quot;proportional formulas&quot;)
h2 &lt;- hist_scores(rohrer$inequality) + ylab(&quot;solving inequalities&quot;)
h3 &lt;- hist_scores(rohrer$parentheses) + ylab(&quot;removing parentheses&quot;)
h4 &lt;- hist_scores(rohrer$circle) + ylab(&quot;calculations on circles&quot;)

# patching them together from left to right in two rows
patch2 &lt;- (h1+h2) / (h3+h4)

patch2 + plot_annotation(
  title = &#39;The effect of interleaving declines for recently blocked topics&#39;,
)</code></pre>
<p><img src="/post/2021-03-13-mixing-up-math-part-1/index.en_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The difference in performance seems to decline for topics that were covered more recently in the <code>blocked</code> group. This is unsurprising. More interestingly, the <code>interleaving</code> group seems to do better even for the questions on circles that were just covered in the blocked group.</p>
<p>If we artificially make the discrete data jump around a little, we can pretend it is continuous and make a scatterplot. We also calculate the means for the two conditions and draw a line between them.</p>
<pre class="r"><code># Write function for plotting scores per math topic
scores_topic &lt;- function(topic) {ggplot(rohrer, aes(x=factor(Group))) +
  geom_jitter(aes(y=topic), width=0.05, alpha=0.1) +
  stat_summary(aes(y = topic,group=1), fun.y=mean, colour=&quot;red&quot;, geom=&quot;line&quot;,group=1, size=1) +
  theme_classic()
}

# plug in the scores per topic
s1 &lt;- scores_topic(rohrer$prop_formula) +
  ylab(&quot;points&quot;) + xlab(NULL) + ggtitle(&quot;formulas&quot;)</code></pre>
<pre><code>## Warning: `fun.y` is deprecated. Use `fun` instead.</code></pre>
<pre class="r"><code>s2 &lt;- scores_topic(rohrer$inequality) + xlab(NULL) + ylab(NULL) + ggtitle(&quot;inequalities&quot;)</code></pre>
<pre><code>## Warning: `fun.y` is deprecated. Use `fun` instead.</code></pre>
<pre class="r"><code>s3 &lt;- scores_topic(rohrer$parentheses) + 
  ylab(&quot;points&quot;) +  xlab(NULL) + ggtitle(&quot;parentheses&quot;)</code></pre>
<pre><code>## Warning: `fun.y` is deprecated. Use `fun` instead.</code></pre>
<pre class="r"><code>s4 &lt;- scores_topic(rohrer$circle) +  xlab(NULL) + ylab(NULL) + ggtitle(&quot;circles&quot;)</code></pre>
<pre><code>## Warning: `fun.y` is deprecated. Use `fun` instead.</code></pre>
<pre class="r"><code># order the graphs
patch3 &lt;- (s1 + s2) / (s3+ s4)
patch3 + plot_annotation(
  title = &quot;Points scored per math topic&quot;
)</code></pre>
<p><img src="/post/2021-03-13-mixing-up-math-part-1/index.en_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The slope of the lines give us a sense about the rate of increase by interleaving questions and more clearly indicate that the effect of interleaving declines for topics that have been practiced in the blocked group more recently.</p>
<p>We also note that the mean for points scored on questions about formulas is living in empty space. With regard to this topic the mean gives a poor summary of what is going on. It would seem that for this topic students either get it or not. We see that the interleaving condition moves students away from the no points group to the 4 points group. This binary nature would suggest that a proportion (of students who got 3 or 4 questions correct) would be a better way to describe and later model the data than the mean. However, for the other questions the mean seems to be a fine summary. And when we add up the points on all topics, we see the points are quite evenly distributed.</p>
<pre class="r"><code># input total points scored into the scores_topic function
scores_topic(rohrer$total) + xlab(NULL) + ylab(&quot;points&quot;) + 
  ggtitle(&quot;points on math test in total&quot;)</code></pre>
<pre><code>## Warning: `fun.y` is deprecated. Use `fun` instead.</code></pre>
<p><img src="/post/2021-03-13-mixing-up-math-part-1/index.en_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>We will stick with the mean then when we turn to inference in part 2.</p>
</div>
